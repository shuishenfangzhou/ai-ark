"""
DeepSeek API æœåŠ¡ - è¯­ä¹‰æœç´¢ä¸å·¥å…·æ¨è
ä½¿ç”¨ DeepSeek Embedding å®ç°åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½æ¨è
ä¸ OpenAI API å…¼å®¹
"""

import os
import json
import numpy as np
from typing import List, Dict, Optional
from datetime import datetime

# å°è¯•å¯¼å…¥ OpenAI SDK (DeepSeek å…¼å®¹)
try:
    from openai import OpenAI
    OPENAI_SDK_AVAILABLE = True
except ImportError:
    OPENAI_SDK_AVAILABLE = False
    print("âš ï¸ openai SDK æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")


class DeepSeekService:
    """DeepSeek API æœåŠ¡ç±» - æä¾›è¯­ä¹‰æœç´¢å’Œæ™ºèƒ½æ¨èåŠŸèƒ½"""
    
    def __init__(self):
        self.api_key = os.getenv("DEEPSEEK_API_KEY", "")
        self.embedding_model = os.getenv("DEEPSEEK_EMBEDDING_MODEL", "deepseek-embed")
        self.chat_model = os.getenv("DEEPSEEK_CHAT_MODEL", "deepseek-chat")
        self.base_url = "https://api.deepseek.com"
        self.embedding_cache = {}
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if self.api_key and OPENAI_SDK_AVAILABLE:
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            print("âœ… DeepSeek API å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
        else:
            self.client = None
            if not self.api_key:
                print("âš ï¸ DEEPSEEK_API_KEY æœªé…ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            if not OPENAI_SDK_AVAILABLE:
                print("âš ï¸ openai SDK æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        
        # åŠ è½½å·¥å…·æ•°æ®
        self.tools_data = self._load_tools()
    
    def _load_tools(self) -> List[Dict]:
        """åŠ è½½å·¥å…·æ•°æ®"""
        tools_path = os.path.join(
            os.path.dirname(__file__),
            "..", "..", "public", "toolsData.json"
        )
        
        try:
            with open(tools_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get("tools", [])
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å·¥å…·æ•°æ®å¤±è´¥: {e}")
            return []
    
    async def generate_embedding(self, text: str) -> List[float]:
        """
        ç”Ÿæˆæ–‡æœ¬çš„å‘é‡åµŒå…¥
        
        Args:
            text: è¾“å…¥æ–‡æœ¬ (å·¥å…·åç§° + æè¿°)
        
        Returns:
            1024 ç»´å‘é‡ (DeepSeek embedding)
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = hash(text)
        if cache_key in self.embedding_cache:
            return self.embedding_cache[cache_key]
        
        if self.client and OPENAI_SDK_AVAILABLE:
            try:
                response = self.client.embeddings.create(
                    model=self.embedding_model,
                    input=text
                )
                embedding = response.data[0].embedding
                
                # ç¼“å­˜ç»“æœ
                self.embedding_cache[cache_key] = embedding
                return embedding
                
            except Exception as e:
                print(f"âš ï¸ DeepSeek Embedding API é”™è¯¯: {e}")
                # å›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼
                return self._mock_embedding(text)
        else:
            # æ¨¡æ‹Ÿæ¨¡å¼
            return self._mock_embedding(text)
    
    def _mock_embedding(self, text: str) -> List[float]:
        """
        ç”Ÿæˆæ¨¡æ‹ŸåµŒå…¥å‘é‡ (ç”¨äºæµ‹è¯•)
        åŸºäºæ–‡æœ¬çš„ hash ç”Ÿæˆç¡®å®šæ€§å‘é‡
        """
        np.random.seed(hash(text) % 2**32)
        embedding = np.random.randn(1024).tolist()
        
        # å½’ä¸€åŒ–
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = [x / norm for x in embedding]
        
        # ç¼“å­˜
        cache_key = hash(text)
        self.embedding_cache[cache_key] = embedding
        
        return embedding
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        v1 = np.array(vec1)
        v2 = np.array(vec2)
        
        dot_product = np.dot(v1, v2)
        norm_v1 = np.linalg.norm(v1)
        norm_v2 = np.linalg.norm(v2)
        
        if norm_v1 == 0 or norm_v2 == 0:
            return 0.0
        
        return float(dot_product / (norm_v1 * norm_v2))
    
    async def semantic_search(
        self,
        query: str,
        category: Optional[str] = None,
        top_k: int = 5,
        min_score: float = 0.3
    ) -> List[Dict]:
        """
        è¯­ä¹‰æœç´¢å·¥å…·
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            category: å¯é€‰çš„åˆ†ç±»ç­›é€‰
            top_k: è¿”å›ç»“æœæ•°é‡
            min_score: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
        
        Returns:
            æ’åºåçš„å·¥å…·åˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°
        """
        if not self.tools_data:
            return []
        
        print(f"ğŸ” è¯­ä¹‰æœç´¢: '{query}' (åˆ†ç±»: {category or 'å…¨éƒ¨'})")
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = await self.generate_embedding(query)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        scored_tools = []
        for tool in self.tools_data:
            # åˆ†ç±»ç­›é€‰
            if category and tool.get("category") != category:
                continue
            
            # æ„å»ºå·¥å…·æ–‡æœ¬
            tool_text = f"{tool.get('name', '')} {tool.get('desc', '')}"
            if tool.get("tags"):
                tool_text += f" {' '.join(tool['tags'])}"
            
            # ç”Ÿæˆå·¥å…·å‘é‡
            tool_embedding = await self.generate_embedding(tool_text)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.cosine_similarity(query_embedding, tool_embedding)
            
            if similarity >= min_score:
                scored_tools.append({
                    **tool,
                    "score": round(similarity, 4),
                    "match_reason": self._generate_match_reason(query, tool, similarity)
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        scored_tools.sort(key=lambda x: x["score"], reverse=True)
        
        # è¿”å› top_k
        results = scored_tools[:top_k]
        
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å·¥å…·")
        
        return results
    
    def _generate_match_reason(self, query: str, tool: Dict, score: float) -> str:
        """ç”ŸæˆåŒ¹é…åŸå› è¯´æ˜"""
        score_percent = int(score * 100)
        
        if score >= 0.7:
            strength = "é«˜åº¦ç›¸å…³"
        elif score >= 0.5:
            strength = "è¾ƒå¼ºç›¸å…³"
        else:
            strength = "ä¸€èˆ¬ç›¸å…³"
        
        return f"ä¸ã€Œ{query}ã€{strength} (åŒ¹é…åº¦: {score_percent}%)"
    
    async def get_recommendations(
        self,
        user_query: str,
        user_context: Optional[Dict] = None,
        max_recommendations: int = 5
    ) -> Dict:
        """
        è·å–æ™ºèƒ½æ¨è
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢æˆ–éœ€æ±‚æè¿°
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ (å½“å‰åˆ†ç±»ã€åå¥½ç­‰)
            max_recommendations: æœ€å¤§æ¨èæ•°é‡
        
        Returns:
            æ¨èç»“æœï¼ŒåŒ…å«å·¥å…·åˆ—è¡¨å’Œæ¨èç†ç”±
        """
        category = user_context.get("category") if user_context else None
        
        # æ‰§è¡Œè¯­ä¹‰æœç´¢
        recommendations = await self.semantic_search(
            query=user_query,
            category=category,
            top_k=max_recommendations,
            min_score=0.3
        )
        
        # ç”Ÿæˆæ€»ä½“æ¨èç†ç”±
        if recommendations:
            top_tool = recommendations[0]
            recommendation_summary = (
                f"åŸºäºæ‚¨çš„éœ€æ±‚ã€Œ{user_query}ã€ï¼Œ"
                f"ä¸ºæ‚¨æ¨èä»¥ä¸‹ {len(recommendations)} æ¬¾AIå·¥å…·ï¼Œ"
                f"ç¬¬ä¸€æ¬¾ã€Œ{top_tool['name']}ã€åŒ¹é…åº¦é«˜è¾¾ {int(top_tool['score'] * 100)}%ã€‚"
            )
        else:
            recommendation_summary = (
                f"æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°ä¸ã€Œ{user_query}ã€é«˜åº¦åŒ¹é…çš„å·¥å…·ã€‚"
                "è¯·å°è¯•å…¶ä»–å…³é”®è¯æˆ–æµè§ˆåˆ†ç±»ã€‚"
            )
        
        return {
            "query": user_query,
            "recommendations": recommendations,
            "summary": recommendation_summary,
            "total_found": len(recommendations),
            "timestamp": datetime.now().isoformat()
        }
    
    async def get_categories(self) -> List[Dict]:
        """è·å–åˆ†ç±»åˆ—è¡¨"""
        tools_path = os.path.join(
            os.path.dirname(__file__),
            "..", "..", "public", "toolsData.json"
        )
        
        try:
            with open(tools_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get("categories", [])
        except Exception:
            return []
    
    async def get_tools_by_category(self, category_id: str, limit: int = 50) -> List[Dict]:
        """æŒ‰åˆ†ç±»è·å–å·¥å…·"""
        tools = [t for t in self.tools_data if t.get("category") == category_id]
        return tools[:limit]


# å•ä¾‹å®ä¾‹
_deepseek_service = None

def get_deepseek_service() -> DeepSeekService:
    """è·å– DeepSeek æœåŠ¡å•ä¾‹"""
    global _deepseek_service
    if _deepseek_service is None:
        _deepseek_service = DeepSeekService()
    return _deepseek_service
