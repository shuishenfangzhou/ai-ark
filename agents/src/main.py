"""
AI Tools Auto-Updater - Main Entry Point
è‡ªåŠ¨åŒ– AI å·¥å…·æ›´æ–°ç³»ç»Ÿ
"""
import os
import sys
import json
import re  # æ·»åŠ  re æ¨¡å—å¯¼å…¥
import asyncio
from datetime import datetime
from pathlib import Path

# æ·»åŠ  src ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models import AITool, ToolsCollection
from deepseek import DeepSeekLLM
from scrapers import GitHubTrendingScraper, ProductHuntScraper


class AIToolsUpdater:
    """AI å·¥å…·è‡ªåŠ¨æ›´æ–°å™¨"""
    
    def __init__(self):
        self.llm = None
        self.collection = ToolsCollection()
        self.data_dir = self._get_data_dir()
    
    def _get_data_dir(self) -> Path:
        """è·å–æ•°æ®ç›®å½•"""
        # ä»é¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾ data ç›®å½•
        current_dir = Path(__file__).parent
        data_dir = current_dir.parent.parent / 'data'
        
        # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        data_dir.mkdir(exist_ok=True)
        return data_dir
    
    def _load_existing_data(self) -> ToolsCollection:
        """åŠ è½½ç°æœ‰æ•°æ®"""
        tools_file = self.data_dir / 'tools.json'
        
        if tools_file.exists():
            try:
                with open(tools_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return ToolsCollection(**data)
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        
        return ToolsCollection()
    
    def _save_data(self, collection: ToolsCollection):
        """ä¿å­˜æ•°æ®"""
        tools_file = self.data_dir / 'tools.json'
        
        with open(tools_file, 'w', encoding='utf-8') as f:
            json.dump(collection.model_dump(), f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {tools_file}")
    
    async def initialize_llm(self):
        """åˆå§‹åŒ– LLM"""
        try:
            self.llm = DeepSeekLLM()
            print("âœ“ DeepSeek LLM åˆå§‹åŒ–æˆåŠŸ")
        except ValueError as e:
            print(f"âš ï¸ DeepSeek LLM åˆå§‹åŒ–å¤±è´¥: {e}")
            print("  å°†è·³è¿‡ AI åˆ†ææ­¥éª¤")
    
    async def fetch_all_sources(self) -> list:
        """ä»æ‰€æœ‰æ¥æºæŠ“å–æ•°æ®"""
        print("\nğŸ“¡ å¼€å§‹æŠ“å–æ•°æ®...")
        
        all_tools = []
        
        # 1. GitHub Trending
        print("\nğŸ” æŠ“å– GitHub Trending...")
        github_scraper = GitHubTrendingScraper()
        github_tools = await github_scraper.fetch()
        await github_scraper.close()
        print(f"âœ“ GitHub: è·å–åˆ° {len(github_tools)} ä¸ªé¡¹ç›®")
        all_tools.extend(github_tools)
        
        # 2. Product Hunt
        print("\nğŸ” æŠ“å– Product Hunt...")
        ph_scraper = ProductHuntScraper()
        ph_tools = await ph_scraper.fetch()
        await ph_scraper.close()
        print(f"âœ“ Product Hunt: è·å–åˆ° {len(ph_tools)} ä¸ªäº§å“")
        all_tools.extend(ph_tools)
        
        return all_tools
    
    async def analyze_tools(self, tools: list) -> list:
        """ä½¿ç”¨ AI åˆ†æå·¥å…·"""
        if not self.llm:
            print("\nâš ï¸ è·³è¿‡ AI åˆ†æï¼ˆLLM æœªåˆå§‹åŒ–ï¼‰")
            return tools
        
        print(f"\nğŸ¤– å¼€å§‹ AI åˆ†æ ({len(tools)} ä¸ªå·¥å…·)...")
        
        analyzed_tools = []
        batch_size = 5
        
        for i in range(0, len(tools), batch_size):
            batch = tools[i:i + batch_size]
            
            for tool in batch:
                try:
                    enriched = await self._analyze_tool(tool)
                    analyzed_tools.append(enriched)
                    print(f"  âœ“ {tool.get('name', 'Unknown')}")
                except Exception as e:
                    print(f"  âœ— åˆ†æå¤±è´¥: {e}")
                    analyzed_tools.append(tool)
            
            # é¿å… API é™æµ
            if i + batch_size < len(tools):
                await asyncio.sleep(1)
        
        return analyzed_tools
    
    async def _analyze_tool(self, tool: dict) -> dict:
        """åˆ†æå•ä¸ªå·¥å…·"""
        if not self.llm:
            return tool
        
        try:
            result = self.llm.analyze_tool(tool)
            return result
        except Exception:
            return tool
    
    async def merge_and_deduplicate(self, new_tools: list, 
                                     existing: ToolsCollection) -> ToolsCollection:
        """åˆå¹¶å¹¶å»é‡"""
        print("\nğŸ”„ åˆå¹¶æ•°æ®...")
        
        merged = existing
        
        for tool_data in new_tools:
            try:
                # ç”Ÿæˆå”¯ä¸€ ID
                tool_id = self._generate_id(tool_data)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if any(t.id == tool_id for t in merged.tools):
                    continue
                
                # åˆ›å»ºå·¥å…·å¯¹è±¡
                tool = AITool(**tool_data)
                merged.add_tool(tool)
                
            except Exception as e:
                print(f"  âš ï¸ å¤„ç†å·¥å…·å¤±è´¥: {e}")
                continue
        
        print(f"âœ“ åˆå¹¶å®Œæˆ: å…± {merged.total_count} ä¸ªå·¥å…·")
        return merged
    
    def _generate_id(self, tool: dict) -> str:
        """ç”Ÿæˆå”¯ä¸€ ID"""
        url = tool.get('url', '')
        name = tool.get('name', 'unknown')
        
        # ä» URL æå–æ ‡è¯†
        if 'github.com' in url:
            # GitHub: ä½¿ç”¨ä»“åº“è·¯å¾„
            match = re.search(r'github\.com/([^/]+/[^/]+)', url)
            if match:
                return f"github-{match.group(1).replace('/', '-')}"
        
        elif 'producthunt.com' in url:
            # Product Hunt: ä½¿ç”¨ slug
            match = re.search(r'producthunt\.com/posts/([^/]+)', url)
            if match:
                return f"ph-{match.group(1)}"
        
        # é»˜è®¤: ä½¿ç”¨åç§°
        return f"tool-{name.lower().replace(' ', '-').replace('_', '-')}"
    
    async def run(self):
        """è¿è¡Œæ›´æ–°æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ AI Tools Auto-Updater v2.0")
        print("=" * 60)
        
        start_time = datetime.now()
        
        try:
            # 1. åŠ è½½ç°æœ‰æ•°æ®
            print("\nğŸ“‚ åŠ è½½ç°æœ‰æ•°æ®...")
            existing = self._load_existing_data()
            print(f"âœ“ å·²åŠ è½½ {existing.total_count} ä¸ªå·¥å…·")
            
            # 2. åˆå§‹åŒ– LLM
            await self.initialize_llm()
            
            # 3. æŠ“å–æ–°æ•°æ®
            new_tools = await self.fetch_all_sources()
            
            if not new_tools:
                print("\nâš ï¸ æœªè·å–åˆ°æ–°æ•°æ®")
                return
            
            # 4. AI åˆ†æ
            analyzed_tools = await self.analyze_tools(new_tools)
            
            # 5. åˆå¹¶å»é‡
            merged = await self.merge_and_deduplicate(analyzed_tools, existing)
            
            # 6. ä¿å­˜ç»“æœ
            self._save_data(merged)
            
            # 7. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            elapsed = (datetime.now() - start_time).total_seconds()
            print("\n" + "=" * 60)
            print("ğŸ“Š æ›´æ–°æŠ¥å‘Š")
            print("=" * 60)
            print(f"  åŸæœ‰å·¥å…·: {existing.total_count}")
            print(f"  æ–°å¢å·¥å…·: {len(new_tools)}")
            print(f"  æœ€ç»ˆæ•°é‡: {merged.total_count}")
            print(f"  è€—æ—¶: {elapsed:.1f} ç§’")
            print("=" * 60)
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            raise


async def main():
    """ä¸»å…¥å£"""
    updater = AIToolsUpdater()
    await updater.run()


if __name__ == "__main__":
    asyncio.run(main())
