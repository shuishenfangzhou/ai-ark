"""
Dead Link Checker
å®šæœŸæ£€æµ‹ tools.json ä¸­çš„é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
"""
import os
import json
import asyncio
import httpx
from typing import List, Dict, Set, Tuple
from datetime import datetime, timedelta
from pathlib import Path


class LinkChecker:
    """æ­»é“¾æ£€æµ‹å™¨"""
    
    def __init__(self, timeout: float = 10.0, max_concurrent: int = 10):
        self.timeout = timeout
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.client = httpx.AsyncClient(timeout=timeout, follow_redirects=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total": 0,
            "alive": 0,
            "dead": 0,
            "redirects": 0,
            "errors": 0,
        }
    
    async def close(self):
        """å…³é—­ HTTP å®¢æˆ·ç«¯"""
        await self.client.aclose()
    
    async def check_single(self, url: str, tool_id: str) -> Dict:
        """æ£€æµ‹å•ä¸ªé“¾æ¥"""
        async with self.semaphore:
            try:
                response = await self.client.head(url, allow_redirects=True)
                status = response.status_code
                
                if status < 400:
                    # æ­£å¸¸
                    self.stats["alive"] += 1
                    return {
                        "tool_id": tool_id,
                        "url": url,
                        "status": status,
                        "alive": True,
                        "message": "OK",
                    }
                elif 400 <= status < 500:
                    # å®¢æˆ·ç«¯é”™è¯¯ï¼ˆ404ç­‰ï¼‰
                    self.stats["dead"] += 1
                    return {
                        "tool_id": tool_id,
                        "url": url,
                        "status": status,
                        "alive": False,
                        "message": f"Client Error ({status})",
                    }
                elif 500 <= status < 600:
                    # æœåŠ¡å™¨é”™è¯¯
                    self.stats["dead"] += 1
                    return {
                        "tool_id": tool_id,
                        "url": url,
                        "status": status,
                        "alive": False,
                        "message": f"Server Error ({status})",
                    }
                else:
                    # å…¶ä»–
                    self.stats["redirects"] += 1
                    return {
                        "tool_id": tool_id,
                        "url": url,
                        "status": status,
                        "alive": True,
                        "message": f"Redirect/Other ({status})",
                    }
                    
            except httpx.TimeoutException:
                self.stats["dead"] += 1
                return {
                    "tool_id": tool_id,
                    "url": url,
                    "status": None,
                    "alive": False,
                    "message": "Timeout",
                }
            except httpx.TooManyRedirects:
                self.stats["errors"] += 1
                return {
                    "tool_id": tool_id,
                    "url": url,
                    "status": None,
                    "alive": False,
                    "message": "Too Many Redirects",
                }
            except Exception as e:
                self.stats["errors"] += 1
                return {
                    "tool_id": tool_id,
                    "url": url,
                    "status": None,
                    "alive": False,
                    "message": str(e)[:100],
                }
    
    async def check_all(self, tools: List[Dict]) -> Tuple[List[Dict], Dict]:
        """æ£€æµ‹æ‰€æœ‰å·¥å…·é“¾æ¥
        
        Returns:
            Tuple: (dead_links_list, stats)
        """
        print(f"\nğŸ” å¼€å§‹æ­»é“¾æ£€æµ‹ ({len(tools)} ä¸ªå·¥å…·)...")
        self.stats["total"] = len(tools)
        
        # åˆ›å»ºä»»åŠ¡
        tasks = []
        for tool in tools:
            url = tool.get("url")
            tool_id = tool.get("id")
            if url and tool_id:
                tasks.append(self.check_single(url, tool_id))
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ•´ç†ç»“æœ
        dead_links = []
        for result in results:
            if isinstance(result, dict) and not result.get("alive"):
                dead_links.append(result)
        
        print(f"âœ“ æ£€æµ‹å®Œæˆ: å­˜æ´» {self.stats['alive']}, æ­»äº¡ {self.stats['dead']}, é”™è¯¯ {self.stats['errors']}")
        
        return dead_links, self.stats.copy()
    
    def generate_report(self, dead_links: List[Dict], stats: Dict) -> str:
        """ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("ğŸ”— æ­»é“¾æ£€æµ‹æŠ¥å‘Š")
        report.append(f"ğŸ“… æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 60)
        report.append("")
        report.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        report.append(f"  æ€»é“¾æ¥æ•°: {stats['total']}")
        report.append(f"  å­˜æ´»é“¾æ¥: {stats['alive']}")
        report.append(f"  æ­»äº¡é“¾æ¥: {stats['dead']}")
        report.append(f"  é‡å®šå‘: {stats['redirects']}")
        report.append(f"  é”™è¯¯: {stats['errors']}")
        report.append("")
        
        if dead_links:
            report.append("âš ï¸ æ­»äº¡é“¾æ¥åˆ—è¡¨")
            report.append("-" * 60)
            for link in dead_links:
                report.append(f"  â€¢ {link['tool_id']}")
                report.append(f"    URL: {link['url']}")
                report.append(f"    åŸå› : {link['message']}")
                report.append("")
        else:
            report.append("âœ… æ²¡æœ‰å‘ç°æ­»äº¡é“¾æ¥ï¼")
        
        report.append("=" * 60)
        
        return "\n".join(report)


async def check_dead_links_main():
    """ä¸»å‡½æ•° - æµ‹è¯•æ­»é“¾æ£€æµ‹"""
    # åŠ è½½å·¥å…·æ•°æ®
    data_file = Path(__file__).parent.parent.parent / 'data' / 'tools.json'
    
    if not data_file.exists():
        print("âŒ tools.json ä¸å­˜åœ¨")
        return
    
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    tools = data.get('tools', [])
    
    # æ‰§è¡Œæ£€æµ‹
    checker = LinkChecker(timeout=10.0, max_concurrent=10)
    dead_links, stats = await checker.check_all(tools)
    await checker.close()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = checker.generate_report(dead_links, stats)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(__file__).parent.parent.parent / 'data' / 'link_check_report.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    asyncio.run(check_dead_links_main())
