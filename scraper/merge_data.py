"""
ç®€åŒ–ç‰ˆæ•°æ®åˆå¹¶è„šæœ¬
å°† ai-bot æ•°æ®ï¼ˆå¿…éœ€ï¼‰å’Œ GitHub æ•°æ®ï¼ˆå¯é€‰ï¼‰åˆå¹¶

ä½¿ç”¨è¯´æ˜:
    python scraper/merge_data.py
"""

import json
import sys
from datetime import datetime
from pathlib import Path

# è·¯å¾„é…ç½®
SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent

AIBOT_DATA_FILE = PROJECT_DIR / "scraper" / "output" / "tools_data.json"
GITHUB_DATA_FILE = PROJECT_DIR / "scraper" / "output" / "github_data.json"
PUBLIC_DATA_FILE = PROJECT_DIR / "public" / "toolsData.json"
DIST_DATA_FILE = PROJECT_DIR / "dist" / "toolsData.json"


def load_aibot_data():
    """åŠ è½½ ai-bot æ•°æ®ï¼ˆå¿…éœ€ï¼‰"""
    print("Loading ai-bot data...")

    if not AIBOT_DATA_FILE.exists():
        print(f"ERROR: ai-bot data file not found: {AIBOT_DATA_FILE}")
        return None

    with open(AIBOT_DATA_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # å…¼å®¹ä¸åŒæ ¼å¼
    if isinstance(data, list):
        tools = data
    elif isinstance(data, dict):
        tools = data.get("tools", data.get("items", []))
    else:
        tools = []

    print(f"  Loaded {len(tools)} ai-bot tools")
    return tools


def load_github_data():
    """åŠ è½½ GitHub æ•°æ®ï¼ˆå¯é€‰ï¼‰"""
    print("Loading GitHub data...")

    if not GITHUB_DATA_FILE.exists():
        print("  No GitHub data file found, skipping")
        return []

    with open(GITHUB_DATA_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    tools = data.get("tools", [])
    print(f"  Loaded {len(tools)} GitHub projects")
    return tools


def convert_to_standard_format(tool, index, source):
    """è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    if source == "ai-bot":
        return {
            "id": tool.get("id", index + 1),
            "name": tool.get("name", ""),
            "category": tool.get("category", "General"),
            "subcategory": tool.get("subcategory", ""),
            "desc": tool.get("desc", "")[:500],
            "url": tool.get("url", ""),
            "tags": tool.get("tags", [])[:10],
            "pricing": tool.get("pricing", "Unknown"),
            "rating": tool.get("rating", 3.0),
            "visits": tool.get("visits", "0"),
            "logo": tool.get("logo", ""),
            "source": "ai-bot.cn"
        }
    else:  # github
        return {
            "id": -(index + 1),
            "name": tool.get("name", ""),
            "category": tool.get("category", "dev"),
            "subcategory": "GitHub Trending",
            "desc": tool.get("desc", "")[:500],
            "url": tool.get("url", tool.get("github_url", "")),
            "tags": tool.get("tags", [])[:10],
            "pricing": "Free",
            "rating": min(5.0, 3.0 + (tool.get("stars", 0) / 100000)),
            "visits": str(tool.get("stars", 0)),
            "logo": tool.get("logo", tool.get("owner", {}).get("avatar_url", "")),
            "source": "github.com",
            "github_url": tool.get("github_url", ""),
            "github_stars": tool.get("stars", 0)
        }


def merge_and_deduplicate(aibot_tools, github_tools):
    """åˆå¹¶å¹¶å»é‡"""
    print("Merging and deduplicating...")

    all_tools = []

    # æ·»åŠ  ai-bot å·¥å…·
    for i, tool in enumerate(aibot_tools):
        converted = convert_to_standard_format(tool, i, "ai-bot")
        all_tools.append(converted)

    # æ·»åŠ  GitHub å·¥å…·
    for i, tool in enumerate(github_tools):
        converted = convert_to_standard_format(tool, i, "github")
        all_tools.append(converted)

    # æŒ‰ URL å»é‡
    seen_urls = set()
    unique_tools = []
    for tool in all_tools:
        url = tool.get("url", "").lower()
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique_tools.append(tool)

    print(f"  Total unique tools: {len(unique_tools)}")
    return unique_tools


def build_categories(tools):
    """æ„å»ºåˆ†ç±»"""
    print("Building categories...")

    category_map = {}
    for tool in tools:
        cat_id = tool.get("category", "General")
        if cat_id not in category_map:
            category_map[cat_id] = {
                "id": cat_id,
                "name": get_category_name(cat_id),
                "icon": get_category_icon(cat_id),
                "count": 0
            }
        category_map[cat_id]["count"] += 1

    categories = list(category_map.values())
    categories.sort(key=lambda x: x["count"], reverse=True)

    print(f"  Categories: {len(categories)}")
    return categories


def get_category_name(cat_id):
    """åˆ†ç±»åç§°æ˜ å°„"""
    names = {
        "dev": "AI Development",
        "image": "AI Image",
        "video": "AI Video",
        "writing": "AI Writing",
        "audio": "AI Audio",
        "office": "AI Office",
        "agents": "AI Agents",
        "chat": "AI Chat",
        "search": "AI Search",
        "design": "AI Design",
        "learning": "AI Learning",
        "models": "AI Models",
        "General": "General"
    }
    return names.get(cat_id, cat_id.title())


def get_category_icon(cat_id):
    """åˆ†ç±»å›¾æ ‡æ˜ å°„"""
    icons = {
        "dev": "ğŸ’»",
        "image": "ğŸ¨",
        "video": "ğŸ¬",
        "writing": "âœï¸",
        "audio": "ğŸµ",
        "office": "ğŸ“Š",
        "agents": "ğŸ¤–",
        "chat": "ğŸ’¬",
        "search": "ğŸ”",
        "design": "ğŸ¯",
        "learning": "ğŸ“š",
        "models": "ğŸ§ ",
        "General": "ğŸ“¦"
    }
    return icons.get(cat_id, "ğŸ“")


def save_data(tools, categories, aibot_count, github_count):
    """ä¿å­˜æ•°æ®"""
    print("Saving data...")

    final_data = {
        "last_updated": datetime.now().strftime("%Y-%m-%d"),
        "total_tools": len(tools),
        "total_categories": len(categories),
        "sources": {
            "ai-bot.cn": aibot_count,
            "github.com": github_count
        },
        "categories": categories,
        "tools": tools
    }

    # ä¿å­˜åˆ° public
    PUBLIC_DATA_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(PUBLIC_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    print(f"  Saved: {PUBLIC_DATA_FILE}")

    # ä¿å­˜åˆ° dist
    DIST_DATA_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(DIST_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    print(f"  Saved: {DIST_DATA_FILE}")

    return final_data


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("Data Merge Script")
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    print()

    # åŠ è½½æ•°æ®
    aibot_tools = load_aibot_data()
    if aibot_tools is None:
        print("ERROR: Failed to load ai-bot data")
        sys.exit(1)

    github_tools = load_github_data()

    # åˆå¹¶
    unique_tools = merge_and_deduplicate(aibot_tools, github_tools)

    # æ„å»ºåˆ†ç±»
    categories = build_categories(unique_tools)

    # ä¿å­˜
    save_data(unique_tools, categories, len(aibot_tools), len(github_tools))

    print()
    print("=" * 50)
    print("SUCCESS!")
    print(f"Total tools: {len(unique_tools)}")
    print(f"Categories: {len(categories)}")
    print("=" * 50)


if __name__ == "__main__":
    main()
