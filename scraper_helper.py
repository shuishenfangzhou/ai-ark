import os
import json
import time
import random
import urllib.request
import ssl
from urllib.parse import urlparse

# --- é…ç½® ---
DATA_FILE = "js/tools_data.js"
ASSETS_DIR = "assets/logos"
# æ¨¡æ‹Ÿçš„æ•°æ®æºï¼ˆåœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œä¼šæ˜¯çˆ¬è™«é€»è¾‘ï¼‰
# ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†ç”Ÿæˆå¤§é‡æ¨¡æ‹Ÿæ•°æ®ï¼Œæ··åˆçœŸå®æ•°æ®
MOCK_COUNT = 1000 

# å¿½ç•¥ SSL
ssl._create_default_https_context = ssl._create_unverified_context

# åŸºç¡€çœŸå®æ•°æ® (ä½œä¸ºç§å­)
SEED_TOOLS = [
    {"name": "Jasper", "cat": "text", "desc": "ä¸“ä¸ºè¥é”€äººå‘˜è®¾è®¡çš„AIå†™ä½œåŠ©æ‰‹ã€‚", "url": "https://www.jasper.ai", "tags": ["è¥é”€", "ä»˜è´¹"]},
    {"name": "Copy.ai", "cat": "text", "desc": "å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡è¥é”€æ–‡æ¡ˆã€‚", "url": "https://www.copy.ai", "tags": ["æ–‡æ¡ˆ", "å…è´¹è¯•ç”¨"]},
    {"name": "Firefly", "cat": "image", "desc": "Adobeæ¨å‡ºçš„åˆ›æ„ç”Ÿæˆå¼AIæ¨¡å‹ã€‚", "url": "https://firefly.adobe.com", "tags": ["è®¾è®¡", "Adobe"]},
    {"name": "Synthesia", "cat": "video", "desc": "AIè§†é¢‘ç”Ÿæˆå¹³å°ï¼Œåªéœ€è¾“å…¥æ–‡æœ¬ã€‚", "url": "https://www.synthesia.io", "tags": ["æ•°å­—äºº", "ä»˜è´¹"]},
    {"name": "Murf.ai", "cat": "audio", "desc": "å°†æ–‡æœ¬è½¬æ¢ä¸ºé€¼çœŸçš„è¯­éŸ³æ—ç™½ã€‚", "url": "https://murf.ai", "tags": ["é…éŸ³", "ä¸“ä¸š"]},
    {"name": "Otter.ai", "cat": "audio", "desc": "AIä¼šè®®è®°å½•ä¸è½¬å½•å·¥å…·ã€‚", "url": "https://otter.ai", "tags": ["ä¼šè®®", "æ•ˆç‡"]},
    {"name": "Beautiful.ai", "cat": "office", "desc": "å‡ åˆ†é’Ÿå†…åˆ¶ä½œç²¾ç¾çš„æ¼”ç¤ºæ–‡ç¨¿ã€‚", "url": "https://www.beautiful.ai", "tags": ["PPT", "è®¾è®¡"]},
    {"name": "Tome", "cat": "office", "desc": "AIé©±åŠ¨çš„å™äº‹æ ¼å¼ï¼Œé‡å¡‘PPTã€‚", "url": "https://tome.app", "tags": ["PPT", "åˆ›æ–°"]},
    {"name": "Tabnine", "cat": "code", "desc": "AIä»£ç è¡¥å…¨åŠ©æ‰‹ï¼Œæ”¯æŒæ‰€æœ‰IDEã€‚", "url": "https://www.tabnine.com", "tags": ["ç¼–ç¨‹", "è¡¥å…¨"]},
    {"name": "Replit Ghostwriter", "cat": "code", "desc": "é›†æˆåœ¨Replitä¸­çš„AIç¼–ç¨‹æ­æ¡£ã€‚", "url": "https://replit.com", "tags": ["äº‘ç«¯", "IDE"]},
]

CATEGORIES = ["text", "image", "video", "audio", "code", "office", "search", "agent", "dev", "learn"]
PRICING = ["å…è´¹", "ä»˜è´¹", "å…è´¹è¯•ç”¨", "å¼€æº"]

def generate_large_dataset():
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {MOCK_COUNT} æ¡æ¨¡æ‹Ÿæ•°æ®...")
    
    # 1. è¯»å–ç°æœ‰çš„ tools_data.js ä¸­çš„æ•°æ® (å¦‚æœæœ‰)
    existing_data = []
    try:
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            content = f.read()
            # è¿™æ˜¯ä¸€ä¸ªéå¸¸ç²—ç³™çš„è§£æï¼Œå‡è®¾æ ¼å¼æ˜¯æ ‡å‡†çš„ `const aiToolsData = [...];`
            start = content.find("[")
            end = content.rfind("]") + 1
            if start != -1 and end != -1:
                existing_data = json.loads(content[start:end])
                print(f"ğŸ“¦ è¯»å–åˆ°ç°æœ‰æ•°æ®: {len(existing_data)} æ¡")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰æ•°æ® (å¯èƒ½æ˜¯é¦–æ¬¡è¿è¡Œ): {e}")

    final_data = existing_data.copy()
    current_count = len(final_data)
    
    # 2. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¡«è¡¥å‰©ä½™ç©ºç¼º
    seed_idx = 0
    while current_count < MOCK_COUNT:
        seed = SEED_TOOLS[seed_idx % len(SEED_TOOLS)]
        
        # å˜å¼‚ç”Ÿæˆ
        new_id = current_count + 1
        suffix = f" {random.randint(100, 999)}"
        new_name = seed["name"] + suffix
        new_cat = seed["cat"]
        # éšæœºåˆ†é…ç±»åˆ«ä»¥ä¸°å¯Œæ•°æ®
        if random.random() > 0.7:
            new_cat = random.choice(CATEGORIES)
            
        tool_entry = {
            "id": new_id,
            "name": new_name,
            "category": new_cat,
            "desc": seed["desc"] + f" (æ¨¡æ‹Ÿæ•°æ® #{new_id})",
            "url": seed["url"],
            "tags": seed["tags"] + [random.choice(["çƒ­é—¨", "æ–°", "æ¨è"])],
            "pricing": random.choice(PRICING),
            "visits": f"{random.randint(1, 500)}K+",
            "rating": round(random.uniform(3.5, 5.0), 1),
            # ä½¿ç”¨ UI Avatars ç”Ÿæˆéšæœºé¢œè‰²å¤´åƒï¼Œé¿å…ä¸‹è½½å¤§é‡å›¾ç‰‡
            "logo": f"https://ui-avatars.com/api/?name={new_name}&background=random&color=fff&size=128"
        }
        
        final_data.append(tool_entry)
        current_count += 1
        seed_idx += 1

    # 3. å†™å…¥æ–‡ä»¶
    js_content = f"""
// ==========================================
// è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶ - åŒ…å«çˆ¬è™«æŠ“å–/æ¨¡æ‹Ÿæ•°æ®
// ç”Ÿæˆæ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S")}
// å·¥å…·æ€»æ•°: {len(final_data)}
// ==========================================
const aiToolsData = {json.dumps(final_data, indent=4, ensure_ascii=False)};
"""
    
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        f.write(js_content)
    
    print(f"\nâœ¨ æ•°æ®ç”Ÿæˆå®Œæ¯•ï¼å·²å†™å…¥ {DATA_FILE}")
    print(f"ğŸ“Š æ€»è®¡å·¥å…·: {len(final_data)} ä¸ª")

if __name__ == "__main__":
    generate_large_dataset()
